{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa33d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import LancasterStemmer, PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c1d0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Gateson\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure you have the required resources\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c631db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization is a transformative process in the digital world, where sensitive data, such as credit card numbers or personal identification, is replaced with a unique identifier known as a token. This token, which has no exploitable value on its own, can be used in place of the original data, significantly enhancing security. Tokenization is widely used in industries like finance and healthcare to protect sensitive information from unauthorized access. By converting valuable data into tokens, companies can safely store and process information while reducing the risk of data breaches. This process not only safeguards privacy but also ensures compliance with data protection regulations, making it an essential tool in the modern digital landscape.\n"
     ]
    }
   ],
   "source": [
    "text_file = open(\"C:/Users/Gateson/Downloads/c.txt\")\n",
    "text = text_file.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fb9f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text into words\n",
    "words = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63c6f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stemmers\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06ee2adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancaster Stemmer Result:\n",
      "tok is a transform process in the digit world , wher sensit dat , such as credit card numb or person id , is replac with a un ident known as a tok . thi tok , which has no exploit valu on it own , can be us in plac of the origin dat , sign enh sec . tok is wid us in industry lik fin and healthc to protect sensit inform from unauth access . by convert valu dat into tok , company can saf stor and process inform whil reduc the risk of dat breach . thi process not on safeguard priv but also ens comply with dat protect reg , mak it an ess tool in the modern digit landscap .\n"
     ]
    }
   ],
   "source": [
    "# Apply Lancaster Stemmer\n",
    "lancaster_stems = [lancaster_stemmer.stem(word) for word in words]\n",
    "print(\"Lancaster Stemmer Result:\")\n",
    "print(\" \".join(lancaster_stems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d8e782d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Porter Stemmer Result:\n",
      "token is a transform process in the digit world , where sensit data , such as credit card number or person identif , is replac with a uniqu identifi known as a token . thi token , which ha no exploit valu on it own , can be use in place of the origin data , significantli enhanc secur . token is wide use in industri like financ and healthcar to protect sensit inform from unauthor access . by convert valuabl data into token , compani can safe store and process inform while reduc the risk of data breach . thi process not onli safeguard privaci but also ensur complianc with data protect regul , make it an essenti tool in the modern digit landscap .\n"
     ]
    }
   ],
   "source": [
    "# Apply Porter Stemmer\n",
    "porter_stems = [porter_stemmer.stem(word) for word in words]\n",
    "print(\"\\nPorter Stemmer Result:\")\n",
    "print(\" \".join(porter_stems))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0822a97d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
